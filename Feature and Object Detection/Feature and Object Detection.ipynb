{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load(image_path):\n",
    "    return cv2.imread(image_path, 0).astype(float) # 0 reads as grayscale (color would be 1)\n",
    "\n",
    "\n",
    "# Make matplotlib figures appear inline in the\n",
    "# notebook rather than in a new window\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "def display(img, title=None):\n",
    "    # Show image\n",
    "    plt.figure(figsize = (5,5))\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to detect rocket panels and predict the distance to them. The targets will be found in images with names beginning with \"RocketPanelStraightDark\" (16\" and higher so the vision targets are visible) by converting them to grayscale and running a brightness threshold. The targets will then be found using contour mapping. The distance to the targets can be determined as the camera type and therefore vertical FOV is known (except these test images are at 4:3 instead of 16:9 so the FOV numbers I have are probably not perfectly accurate) as is the physical height of the targets which allows for the distance to be calculated. In order for a truly accurate distance to be found, the camera distortion must be known, which is not the case here.\n",
    "\n",
    "This process is commonly applied in FRC, although our team has been using homographies for the last two years which allows us to better identify targets and get more accurate information about the robot's position from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOV @ 4:3 aspect ratio (degrees)\n",
    "VERT_FOV = 41.1\n",
    "HORIZ_FOX = 54.8\n",
    "TAPE_HEIGHT = 5.5 * np.cos(np.deg2rad(14.5)) + 2 * np.sin(np.deg2rad(14.5)) # inches. Expected bbox height\n",
    "# each tape is 5.5 inches long, 2 wide, and at a 14.5 degree angle from the horizontal\n",
    "IMG_HEIGHT = 240\n",
    "IMG_WIDTH = 320\n",
    "\n",
    "# grayscale -- unused because we can do it while loading\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# binary threshold\n",
    "def threshold(img):\n",
    "    return cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)[1] # [0] is just 127\n",
    "\n",
    "# find contours\n",
    "def contours(thresh):\n",
    "    contours, hierarchy = cv2.findContours(thresh.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "# filter for vision target contours\n",
    "def filter_contours(contours):\n",
    "    return sorted(contours, key=cv2.contourArea)[-2:]\n",
    "\n",
    "class Bbox:\n",
    "    def __init__(self, x, y, w, h): # x and y are ctr, w and h are self explanatory\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "\n",
    "# get the bounding box of a contour\n",
    "def get_bbox(contour):\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    return Bbox((x + w) / 2, (y + h) / 2, w, h)\n",
    "\n",
    "def get_dist(bbox):\n",
    "    target_vert_fov = bbox.h * np.deg2rad(VERT_FOV) / IMG_HEIGHT # this is where a linear mapping of pixels to degrees is assumed\n",
    "    dist_px = bbox.h / np.tan(target_vert_fov) # distance in pixels. Assumption: right triangle\n",
    "    px2in = bbox.h / TAPE_HEIGHT\n",
    "    return dist_px / px2in # inches\n",
    "     \n",
    "\n",
    "def dist_from_img(img_str):\n",
    "    start_img = load(img_str)\n",
    "    thresh_img = threshold(start_img)    \n",
    "    contours_array = contours(thresh_img)\n",
    "    filtered_contours = filter_contours(contours_array)\n",
    "    bboxes = [get_bbox(contour) for contour in filtered_contours]\n",
    "    dists = [get_dist(bbox) for bbox in bboxes]\n",
    "    return np.mean(dists)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth: 16, estimation: 16.134966993643857\n",
      "ground truth: 24, estimation: 24.538008980725824\n",
      "ground truth: 36, estimation: 36.82357339855257\n",
      "ground truth: 48, estimation: 49.12234433844229\n",
      "ground truth: 60, estimation: 60.723044690088685\n",
      "ground truth: 72, estimation: 73.4226753374948\n",
      "ground truth: 96, estimation: 175.8835389255266\n"
     ]
    }
   ],
   "source": [
    "test_dists = [16, 24, 36, 48, 60, 72, 96]\n",
    "test_strs = [\"2019VisionImages/RocketPanelStraightDark\" + str(x) + \"in.jpg\" for x in test_dists]\n",
    "for i, test_str in enumerate(test_strs):\n",
    "    print(\"ground truth: \" + str(test_dists[i]) + \", estimation: \" + str(dist_from_img(test_str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results pretty good, especially considering the assumptions made and the fact that these FOV's are kind of sketchy and the actual pixels to degrees mapping is unknown. Additionally, I believe that the ground truth distances are not to the targets but rather to part of the structures that they are attached to, which makes it possible that the first few results are more accurate than they seem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
